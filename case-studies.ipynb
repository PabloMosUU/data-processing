{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colorama import Fore\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = \"../usb/releases/20201018/\"\n",
    "DROPOUTDATADIR = \"../usb/releases/20200302/\"\n",
    "CLIENTSFILE = \"clients.csv.gz\"\n",
    "DROPOUTFILE = \"dropout.csv.gz\"\n",
    "ANSWERID = \"answerId_normalized\"\n",
    "ANSWERIDORIGINAL = \"answerId_original\"\n",
    "ANSWERTEXT = \"answerText\"\n",
    "ANSWERTITLE = \"answerTitle\"\n",
    "CLIENT = \"client\"\n",
    "CLIENTID = \"clientID\"\n",
    "DROPOUT = \"dropout\"\n",
    "QUESTIONNUMBER = \"questionNumber\"\n",
    "REMOVED = \"REMOVED\"\n",
    "COMPLETERCODE = \"2\"\n",
    "DROPOUTCODE = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dropout_ids():\n",
    "    dropout = pd.read_csv(DROPOUTDATADIR+DROPOUTFILE)\n",
    "    dropout_ids = list(dropout[dropout[DROPOUT]==DROPOUTCODE][CLIENTID])\n",
    "    completer_ids = list(dropout[dropout[DROPOUT]==COMPLETERCODE][CLIENTID])\n",
    "    return(dropout_ids,completer_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_ids,completer_ids = read_dropout_ids()\n",
    "len(dropout_ids),len(completer_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: compare metadata of dropouts and completers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENDER = \"geslacht\"\n",
    "AGE = \"leeftijd\"\n",
    "EDUCATION = \"opleidng\"\n",
    "DAY1 = \"dag1\"\n",
    "MAN = \"Man\"\n",
    "WOMAN = \"Vrouw\"\n",
    "ANSWER = \"answer\"\n",
    "COUNT = \"count\"\n",
    "YESNO = \"YESNO\"\n",
    "YESNOIDS = [\"dagritme\",\"dsm2\",\"dsm3\",\"dsm4\",\"dsm5\",\"dsm6\",\"dsm7\",\"dsm8\",\"dsm9\",\"dsm11\",\n",
    "            \"medicijn\",\"drugs\",\"eetdrang\",\"insult\",\"delirium\",\"psych\",\"tabak\",\"canna\",\n",
    "            \"coca\",\"speed\",\"xtc\",\"ghb\",\"opiat\",\"sleep\",\"gok\",\"behversl\",\"halluci\",\n",
    "            \"suicide\",\"wanen\",\"benniet\"]\n",
    "COLUMNS = [{ANSWER:answer, COUNT:1} for answer in [GENDER,EDUCATION,DAY1,AGE]+YESNOIDS]\n",
    "CONVERSION = { GENDER: {WOMAN:0,MAN:1},\n",
    "               EDUCATION: {\"Basisschool\":0,\"LBO/MAVO\":1,\"MBO\":2,\"HAVO/VWO\":3,\"HBO\":4,\"WO\":5,\"REMOVED\":np.nan},\n",
    "               YESNO: {\"Nee\":0,\"Ja\":1}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_binary_answers_numeric(df, column_names, binary_translation_table_in):\n",
    "    data_table = []\n",
    "    processed_clients = []\n",
    "    binary_translation_table = dict(binary_translation_table_in)\n",
    "    column_name_ids = {column_names[i]:i for i in range(0,len(column_names))}\n",
    "    for i in range(0,len(df)):\n",
    "        row = df.iloc[i]\n",
    "        answer_id = row[ANSWERID]\n",
    "        answer_text = cleanup_answer_text(row[ANSWERTEXT])\n",
    "        client_id = row[CLIENT]\n",
    "        if not client_id in processed_clients:\n",
    "            data_table.append(len(column_names)*[np.nan])\n",
    "            processed_clients.append(client_id)\n",
    "        elif client_id != processed_clients[-1]:\n",
    "            print(Fore.RED, f\"make_binary_answers_numeric: cannot happen: 1:{client_id} 2:{processed_clients[-1]}\")\n",
    "        if answer_id in column_names and not pd.isna(answer_text) and answer_text != \"removed\":\n",
    "            if not answer_id in binary_translation_table:\n",
    "                if answer_text == \"nee\" or answer_text == \"ja\":\n",
    "                    binary_translation_table[answer_id] = { \"nee\": 0, \"ja\": 1 }\n",
    "                elif answer_text == \"vrouw\" or answer_text == \"man\":\n",
    "                    binary_translation_table[answer_id] = { \"vrouw\": 0, \"man\": 1 }\n",
    "                else:\n",
    "                    binary_translation_table[answer_id] = { answer_text: 0 }\n",
    "            elif answer_text not in binary_translation_table[answer_id]:\n",
    "                if len(binary_translation_table[answer_id]) == 1:\n",
    "                    binary_translation_table[answer_id][answer_text] = 1\n",
    "                else:\n",
    "                    print(Fore.RED, f\"make_binary_answers_numeric: cannot happen: 1:{answer_id} 2:{answer_text} 3:{binary_translation_table[answer_id]}\")\n",
    "            data_table[-1][column_name_ids[answer_id]] = binary_translation_table[answer_id][answer_text]\n",
    "    return(data_table, binary_translation_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(dropout_ids,completer_ids):\n",
    "    client_data = pd.read_csv(DATADIR+CLIENTSFILE)\n",
    "    dropout_data = client_data[client_data[CLIENT].isin(dropout_ids)]\n",
    "    completer_data = client_data[client_data[CLIENT].isin(completer_ids)]\n",
    "    return(dropout_data,completer_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_data,completer_data = read_data(dropout_ids,completer_ids)\n",
    "all_data = pd.concat([dropout_data,completer_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_data_completeness(dropout_data,completer_data,dropout_ids,completer_ids):\n",
    "    dropout_data_ids = list(dropout_data[CLIENT])\n",
    "    for client_id in dropout_ids:\n",
    "        if client_id not in dropout_data_ids:\n",
    "            print(f\"missing dropout client id: {client_id}\")\n",
    "\n",
    "    completer_data_ids = list(completer_data[CLIENT])\n",
    "    for client_id in completer_ids:\n",
    "        if client_id not in completer_data_ids:\n",
    "            print(f\"missing completer client id: {client_id}\")\n",
    "            \n",
    "verify_data_completeness(dropout_data,completer_data,dropout_ids,completer_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer_values(dropout_data, completer_data, column_name):\n",
    "    nbr_of_dropouts = len(dropout_data.groupby(\"client\").groups)\n",
    "    nbr_of_completers = len(completer_data.groupby(\"client\").groups)\n",
    "    dropout_values = pd.DataFrame(dropout_data[dropout_data[\"answerId_normalized\"]==column_name],columns=[\"answerText\"]).groupby(\"answerText\").size()\n",
    "    completer_values = pd.DataFrame(completer_data[completer_data[\"answerId_normalized\"]==column_name],columns=[\"answerText\"]).groupby(\"answerText\").size()\n",
    "    nbr_of_missing = nbr_of_dropouts+nbr_of_completers\n",
    "    answer_values = {}\n",
    "    for key in dropout_values.index:\n",
    "        if not key in dropout_values:\n",
    "            dropout_values[key] = 0\n",
    "        if not key in completer_values:\n",
    "            completer_values[key] = 0\n",
    "        answer_values[key] = dropout_values[key]+completer_values[key]\n",
    "        nbr_of_missing -= dropout_values[key]+completer_values[key]\n",
    "    answer_values[\"MISSING\"] = nbr_of_missing\n",
    "    return(answer_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Experiment with binary answer classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GESLACHT = \"geslacht\"\n",
    "GESLACHT0 = \"geslacht0\"\n",
    "GESLACHTT0 = \"geslachtt0\"\n",
    "NONQUESTIONS = \"^(goTo[0-9]|ltgeslacht1|doel)$\"\n",
    "EXCEPTIONANSWERID = \"mdoel\"\n",
    "\n",
    "def cleanup_answer_text(text):\n",
    "    if pd.isna(text): return(text)\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(\" *leeftijd in jaren$\", \"\",text)\n",
    "    text = re.sub(\"^niet gedronken$\", \"0\",text)\n",
    "    text = re.sub(\"11 t/m 15\", \"13\",text)\n",
    "    text = re.sub(\"16 t/m 20\", \"18\",text)\n",
    "    text = re.sub(\"21 t/m 25\", \"23\",text)\n",
    "    text = re.sub(\"26 t/m 30\", \"28\",text)\n",
    "    text = re.sub(\"^ja, ik heb deze internetbehandeling al eens gevolgd.$\",\"ja\",text)\n",
    "    text = re.sub(\"\\s+\",\" \",text)\n",
    "    text = text.strip()\n",
    "    return(text)\n",
    "\n",
    "def normalize_answer_id(answer_id, first_answer_id):\n",
    "    if first_answer_id == GESLACHT: \n",
    "        new_answer_id = answer_id\n",
    "    elif first_answer_id == GESLACHT0:\n",
    "        if re.search(\"0h$\",answer_id):\n",
    "            new_answer_id = re.sub(\"0h$\",\"h\",answer_id)\n",
    "        else:\n",
    "            new_answer_id = re.sub(\"0$\",\"\",answer_id)\n",
    "    elif first_answer_id == GESLACHTT0: \n",
    "        new_answer_id = re.sub(\"t0$\",\"\",answer_id)\n",
    "    else: \n",
    "        sys.exit(f\"unknown first answer id: {first_answer_id}!\")\n",
    "    if re.search(\"^(goTo[0-9]|ltgeslacht1|doel)$\",answer_id):\n",
    "        return(\"\")\n",
    "    if (first_answer_id != GESLACHT and new_answer_id == answer_id and \n",
    "        not answer_id == EXCEPTIONANSWERID and not re.search(NONQUESTIONS,answer_id)):\n",
    "        sys.exit(f\"first answer id {first_answer_id} did not change {answer_id}!\")\n",
    "    return(new_answer_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_binary_answer_keys(dropout_data, completer_data):\n",
    "    answer_texts = {}\n",
    "    data = pd.concat([dropout_data,completer_data])\n",
    "    for i in range(0,len(data)):\n",
    "        client_id = data.iloc[i][CLIENT]\n",
    "        answer_text = cleanup_answer_text(data.iloc[i][ANSWERTEXT])\n",
    "        answer_title = cleanup_answer_text(data.iloc[i][ANSWERTITLE])\n",
    "        if pd.isna(answer_title): answer_title = \"\"\n",
    "        answer_id = str(data.iloc[i][ANSWERID])\n",
    "        answer_key = answer_id\n",
    "        if not answer_key in answer_texts.keys(): answer_texts[answer_key] = []\n",
    "        if not answer_text in answer_texts[answer_key] and not pd.isna(answer_text) and not answer_text == \"removed\":\n",
    "            answer_texts[answer_key].append(answer_text)\n",
    "    binary_answer_keys = []\n",
    "    for answer_key in answer_texts:\n",
    "        if len(answer_texts[answer_key]) == 2:\n",
    "            binary_answer_keys.append(answer_key)\n",
    "    return(binary_answer_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_useful_binary_answer_keys(dropout_data, completer_data, binary_answer_keys, show_values=False):\n",
    "    useful_binary_answer_keys = []\n",
    "    for key in binary_answer_keys:\n",
    "        answer_id = key\n",
    "        answer_values = get_answer_values(dropout_data, completer_data, answer_id)\n",
    "        if show_values:\n",
    "            print(\"#####\", answer_id)\n",
    "            for answer_value in answer_values:\n",
    "                print(answer_values[answer_value], answer_value)\n",
    "        nbr_of_values = sum(list(answer_values.values()))\n",
    "        nbr_of_missing_values = sum([answer_values[answer_value] for answer_value in answer_values if answer_value == \"MISSING\" or answer_value == \"REMOVED\"])\n",
    "        if nbr_of_missing_values < 0.5*nbr_of_values:\n",
    "            useful_binary_answer_keys.append(answer_id)\n",
    "    return(useful_binary_answer_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_classif, f_regression\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def remove_nan(X,y):\n",
    "    X_no_nan = []\n",
    "    y_no_nan = []\n",
    "    for i in range(0,len(X)):\n",
    "        if not np.isnan(X[i][0]):\n",
    "            X_no_nan.append([X[i][0]])\n",
    "            y_no_nan.append(y[i])\n",
    "    return(X_no_nan, y_no_nan)\n",
    "\n",
    "def run_anova_classify(dropout_table,completer_table):\n",
    "    X = dropout_table+completer_table\n",
    "    y = len(dropout_table)*[DROPOUTCODE]+len(completer_table)*[COMPLETERCODE]\n",
    "    p_values = []\n",
    "    for i in range(0,len(X[0])):\n",
    "        try:\n",
    "            X_no_nan, y_no_nan = remove_nan([[X[j][i]] for j in range(0,len(X))],y)\n",
    "            F, p_value = f_classif(X_no_nan, y_no_nan)\n",
    "            p_values.extend(p_value)\n",
    "        except:\n",
    "            p_values.append(np.nan)\n",
    "    return(p_values)\n",
    "\n",
    "def column_average(table,column_id):\n",
    "    try:\n",
    "        return(np.average([row[column_id] for row in table if not np.isnan(row[column_id])]))\n",
    "    except:\n",
    "        return(np.nan)\n",
    "\n",
    "def count_non_nan(table, column_id):\n",
    "    return(len([row[column_id] for row in table if not np.isnan(row[column_id])]))\n",
    "\n",
    "def sort_p_values(p_values,column_names,dropout_table,completer_table):\n",
    "    return(pd.DataFrame({column_names[i]:(p_values[i],\n",
    "                                          column_average(completer_table, i),\n",
    "                                          column_average(dropout_table, i),\n",
    "                                          count_non_nan(completer_table, i),\n",
    "                                          count_non_nan(dropout_table, i)\n",
    "                                         ) for i in sorted(range(0,len(p_values)), key=lambda i:p_values[i])},\n",
    "                        index=[\"p_value\", \"average com\", \"average dro\", \"non nan com\", \"non nan dro\"]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_answer_keys = find_binary_answer_keys(dropout_data, completer_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_binary_answer_keys = get_useful_binary_answer_keys(dropout_data, completer_data, binary_answer_keys, show_values=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_table_binary, binary_translation_table_dropout = make_binary_answers_numeric(dropout_data, binary_answer_keys, {})\n",
    "completer_table_binary, binary_translation_table_completer = make_binary_answers_numeric(completer_data, binary_answer_keys, binary_translation_table_dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_translation_table_completer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values = run_anova_classify(dropout_table_binary, completer_table_binary)\n",
    "sort_p_values(p_values, binary_answer_keys, dropout_table_binary, completer_table_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Experiment with numeric answer classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_numeric_answer_keys(dropout_data, completer_data):\n",
    "    numeric_data_seen = {}\n",
    "    other_data_seen = {}\n",
    "    data = pd.concat([dropout_data, completer_data])\n",
    "    for i in range(0,len(data)):\n",
    "        client_id = data.iloc[i][CLIENT]\n",
    "        answer_text = cleanup_answer_text(data.iloc[i][ANSWERTEXT])\n",
    "        answer_title = cleanup_answer_text(data.iloc[i][ANSWERTITLE])\n",
    "        if pd.isna(answer_title): answer_title = \"\"\n",
    "        answer_id = str(data.iloc[i][ANSWERID])\n",
    "        answer_key = answer_id # +\"#\"+answer_title\n",
    "        if not answer_key in numeric_data_seen.keys(): \n",
    "            numeric_data_seen[answer_key] = False\n",
    "            other_data_seen[answer_key] = False\n",
    "        if not pd.isna(answer_text) and not answer_text == \"removed\":\n",
    "            if type(answer_text) == np.float64 or re.search(\"^[0-9]+$\",answer_text): \n",
    "                numeric_data_seen[answer_key] = True\n",
    "            else:\n",
    "                other_data_seen[answer_key] = True\n",
    "    return([answer_key for answer_key in numeric_data_seen if numeric_data_seen[answer_key] and not other_data_seen[answer_key]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_numeric_answers_numeric(df, column_names):\n",
    "    data_table = []\n",
    "    processed_clients = []\n",
    "    column_name_ids = {column_names[i]:i for i in range(0,len(column_names))}\n",
    "    for i in range(0,len(df)):\n",
    "        row = df.iloc[i]\n",
    "        answer_id = row[ANSWERID]\n",
    "        answer_text = cleanup_answer_text(row[ANSWERTEXT])\n",
    "        client_id = row[CLIENT]\n",
    "        if not client_id in processed_clients:\n",
    "            data_table.append(len(column_names)*[np.nan])\n",
    "            processed_clients.append(client_id)\n",
    "        elif client_id != processed_clients[-1]:\n",
    "            print(Fore.RED, f\"make_binary_answers_numeric: cannot happen: 1:{client_id} 2:{processed_clients[-1]}\")\n",
    "        if answer_id in column_names and not pd.isna(answer_text) and answer_text != \"removed\":\n",
    "            data_table[-1][column_name_ids[answer_id]] = float(answer_text)\n",
    "    return(data_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_anova_regression(dropout_table, completer_table):\n",
    "    X = dropout_table+completer_table\n",
    "    y = len(dropout_table)*[int(DROPOUTCODE)]+len(completer_table)*[int(COMPLETERCODE)]\n",
    "    p_values = []\n",
    "    for i in range(0, len(X[0])):\n",
    "        try:\n",
    "            X_no_nan, y_no_nan = remove_nan([[X[j][i]] for j in range(0, len(X))],y)\n",
    "            F, p_value = f_regression(X_no_nan, y_no_nan)\n",
    "            p_values.extend(p_value)\n",
    "        except:\n",
    "            p_values.append(np.nan)\n",
    "    return(p_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_answer_keys = find_numeric_answer_keys(dropout_data, completer_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completer_table_numeric = make_numeric_answers_numeric(completer_data, numeric_answer_keys)\n",
    "dropout_table_numeric = make_numeric_answers_numeric(dropout_data, numeric_answer_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(numeric_answer_keys), len(dropout_table_numeric[0]), len(completer_table_numeric[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values = run_anova_regression(dropout_table_numeric, completer_table_numeric)\n",
    "sort_p_values(p_values, numeric_answer_keys, dropout_table_numeric, completer_table_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Experiment with text answer classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MINANSWERCOUNT = 10\n",
    "MAXPVALUE = 0.01\n",
    "ANSWER = \"answer\"\n",
    "COUNT = \"count\"\n",
    "\n",
    "def get_binary_answers(data):\n",
    "    answers_per_client = {}\n",
    "    for i in range(0,len(data)):\n",
    "        client_id = data.iloc[i][CLIENT]\n",
    "        if not client_id in answers_per_client:\n",
    "            answers_per_client[client_id] = []\n",
    "        answer_id = str(data.iloc[i][ANSWERID])\n",
    "        if re.search(NONQUESTIONS,answer_id): continue\n",
    "        answer_text = cleanup_answer_text(data.iloc[i][ANSWERTEXT])\n",
    "        answer_title = cleanup_answer_text(data.iloc[i][ANSWERTITLE])\n",
    "        if not pd.isna(answer_text): # and answer_text != \"removed\":\n",
    "            if pd.isna(answer_title): answer_title = \"\"\n",
    "            answers_per_client[client_id].append(answer_id+\"#\"+answer_title+\"#\"+answer_text)\n",
    "    return(answers_per_client)\n",
    "\n",
    "def count_answers(binary_answers):\n",
    "    answer_counts = {}\n",
    "    for client_id in binary_answers:\n",
    "        for answer in binary_answers[client_id]:\n",
    "            if answer in answer_counts:\n",
    "                answer_counts[answer] += 1\n",
    "            else:\n",
    "                answer_counts[answer] = 1\n",
    "    return({answer:answer_counts[answer] for answer in sorted(answer_counts.keys(),key=lambda a:answer_counts[a],reverse=True)})\n",
    "\n",
    "def make_binary_table(data,binary_answers):\n",
    "    answer_counts = count_answers(binary_answers)\n",
    "    binary_table = []\n",
    "    answers_used = []\n",
    "    for client_id in data[CLIENT].unique():\n",
    "        binary_table.append([])\n",
    "        for answer in answer_counts:\n",
    "            if answer_counts[answer] >= MINANSWERCOUNT:\n",
    "                if answer in binary_answers[client_id]:\n",
    "                    binary_table[-1].append(1)\n",
    "                else:\n",
    "                    binary_table[-1].append(0)\n",
    "    for answer in answer_counts:\n",
    "        if answer_counts[answer] >= MINANSWERCOUNT:\n",
    "            answers_used.append({ANSWER:answer, COUNT:answer_counts[answer]})\n",
    "    return(binary_table, answers_used)\n",
    "\n",
    "def convert_data_to_binary(dropout_data,completer_data):\n",
    "    all_data = pd.concat([dropout_data,completer_data])\n",
    "    binary_answers = get_binary_answers(all_data)\n",
    "    dropout_table_binary, answers_used = make_binary_table(dropout_data,binary_answers)\n",
    "    completer_table_binary, answers_used = make_binary_table(completer_data,binary_answers)\n",
    "    return(dropout_table_binary, completer_table_binary, answers_used, binary_answers)\n",
    "\n",
    "def select_p_values(p_values,column_names,dropout_table,completer_table):\n",
    "    return({column_names[i][ANSWER]:(p_values[i],column_average(completer_table,i),column_average(dropout_table,i)) \n",
    "            for i in sorted(range(0,len(p_values)),key=lambda i:p_values[i])\n",
    "            if column_average(completer_table,i) < column_average(dropout_table,i) and p_values[i] < MAXPVALUE})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_table_binary, completer_table_binary, answers_used, binary_answers = convert_data_to_binary(dropout_data,completer_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dropout_table_binary[0]),len(completer_table_binary[0]),len(answers_used), len(binary_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values = run_anova(dropout_table_binary,completer_table_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(sort_p_values(p_values,answers_used,dropout_table_binary,completer_table_binary).items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_answer_ids_freqs(dropout_data,completer_data):\n",
    "    all_data = pd.concat([dropout_data,completer_data])\n",
    "    for answer_combi in [\"opiat##nee\",\"opiath##0\",\"mateicn10#10.had je gebrek aan onderdak of had je problemen met huisvesting?#niet / geen\",\n",
    "                         \"national##nederlands\",\"gokken##nee\",\n",
    "                         \"mateicn13#13.had je er moeite mee voor een veilige slaapplaats of voor beschermende kleding te zorgen?#niet / geen\"]:\n",
    "        answer = answer_combi.split(\"#\")[0]\n",
    "        print(answer,\n",
    "              len(all_data[all_data[ANSWERIDORIGINAL]==answer]),\n",
    "              len(all_data[all_data[ANSWERIDORIGINAL]==answer+\"0\"]),\n",
    "              len(all_data[all_data[ANSWERIDORIGINAL]==answer+\"t0\"]))\n",
    "        \n",
    "print_answer_ids_freqs(dropout_data,completer_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_predictors = list(select_p_values(p_values,answers_used,dropout_table_binary,completer_table_binary).keys())\n",
    "print(len(dropout_predictors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dropout_predictor_scores(data,dropout_predictors,binary_answers,questionnaire_types):\n",
    "    scores = []\n",
    "    for client_id in data[CLIENT].unique():\n",
    "        score = 0\n",
    "        for predictor in dropout_predictors:\n",
    "            if predictor in binary_answers[client_id]: \n",
    "                score += 1\n",
    "        scores.append((score,client_id,questionnaire_types[client_id]))\n",
    "    return(scores)\n",
    "\n",
    "def get_questionnaire_types(all_data):\n",
    "    questionnaire_types = {}\n",
    "    for i,row in all_data.iterrows():\n",
    "        client_id = row[CLIENT]\n",
    "        if not client_id in questionnaire_types: questionnaire_types[client_id] = 0\n",
    "        questionnaire_types[client_id] += 1\n",
    "    return(questionnaire_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questionnaire_types = get_questionnaire_types(all_data)\n",
    "dropout_predictor_scores_dropout = get_dropout_predictor_scores(dropout_data,dropout_predictors,binary_answers,questionnaire_types)\n",
    "dropout_predictor_scores_completer = get_dropout_predictor_scores(completer_data,dropout_predictors,binary_answers,questionnaire_types)\n",
    "print([score_tuple[0] for score_tuple in sorted(dropout_predictor_scores_dropout,key=lambda s:s[0],reverse=True)])\n",
    "print([score_tuple[0] for score_tuple in sorted(dropout_predictor_scores_completer,key=lambda s:s[0],reverse=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([score_tuple for score_tuple in sorted(dropout_predictor_scores_dropout,key=lambda s:s[0],reverse=True)][:104])\n",
    "print([score_tuple for score_tuple in sorted(dropout_predictor_scores_completer,key=lambda s:s[0],reverse=True)][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"selected 104: 3 completed: {(104-3)/104}\")\n",
    "print(f\"selected 245: 32 completed: {(245-32)/245}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = pd.DataFrame.from_dict(questionnaire_types,orient=\"index\").groupby(0).groups\n",
    "{g:len(groups[g]) for g in groups}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_shape(table):\n",
    "    print(len(table),len(table[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_columns(dropout_table,completer_table,p_values):\n",
    "    column_average_dropout = []\n",
    "    column_average_completer = []\n",
    "    for i in range(0,len(p_values)):\n",
    "        column_average_dropout.append(column_average(dropout_table,i))\n",
    "        column_average_completer.append(column_average(completer_table,i))\n",
    "    table_in = dropout_table+completer_table\n",
    "    table_out = []\n",
    "    for row_in in table_in:\n",
    "        row_out = [row_in[i] for i in range(0,len(row_in)) \n",
    "                   if p_values[i] < MAXPVALUE and\n",
    "                   column_average_completer[i] < column_average_dropout[i]]\n",
    "        table_out.append(row_out)\n",
    "    return(table_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_dropout_selectors = select_columns(dropout_table_binary,completer_table_binary,p_values)\n",
    "table_dropout_selectors_dropout = table_dropout_selectors[:len(dropout_table_binary)]\n",
    "table_dropout_selectors_completer = table_dropout_selectors[len(dropout_table_binary):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_array = np.array(dropout_table_binary+completer_table_binary)\n",
    "all_data_coordinates = TSNE(n_components=2).fit_transform(all_data_array)\n",
    "dropout_coordinates = all_data_coordinates[:len(dropout_table_binary)]\n",
    "completer_coordinates = all_data_coordinates[len(dropout_table_binary):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_shape(all_data_coordinates)\n",
    "print_shape(completer_coordinates)\n",
    "print_shape(dropout_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig,(ax1,ax2) = plt.subplots(1,2,figsize=(12,4))\n",
    "x = [completer_coordinates[i][0] for i in range(0,len(completer_coordinates))]\n",
    "y = [completer_coordinates[i][1] for i in range(0,len(completer_coordinates))]\n",
    "ax1.scatter(x,y,s=10,label=\"completer\")\n",
    "x = [dropout_coordinates[i][0] for i in range(0,len(dropout_coordinates))]\n",
    "y = [dropout_coordinates[i][1] for i in range(0,len(dropout_coordinates))]\n",
    "ax1.scatter(x,y,s=10,label=\"dropout\")\n",
    "ax1.legend(framealpha=0.5)\n",
    "\n",
    "ax1.set_xticks([])\n",
    "ax1.set_yticks([])\n",
    "ax2.set_xticks([])\n",
    "ax2.set_yticks([])\n",
    "questionnaire_types_list = list(questionnaire_types.values())\n",
    "for questionnaire_type in set(questionnaire_types.values()):\n",
    "    x = [all_data_coordinates[i][0] for i in range(0,len(all_data_coordinates)) if questionnaire_types_list[i] == questionnaire_type] \n",
    "    y = [all_data_coordinates[i][1] for i in range(0,len(all_data_coordinates)) if questionnaire_types_list[i] == questionnaire_type]\n",
    "    ax2.scatter(x,y,s=10,label=questionnaire_type)\n",
    "ax2.legend(framealpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
