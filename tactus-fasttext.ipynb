{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fasttext experiments with tactus data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First import required modules: general Python modules and modules from Orange3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import fasttext\n",
    "import gzip\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/home/erikt/projects/e-mental-health/enron/orange-hackathon/orangehackathon/libs\")\n",
    "import tactusloaderLIB\n",
    "import OWEmailSorterLIB\n",
    "import markduplicatesLIB\n",
    "import removemarkedtextLIB\n",
    "import LIWCLIB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, read the mails from the data set via Orange 3 and store them in the data structure allMails. This takes several minutes so we do not want to do this often."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANODIRECTORY = \"/home/erikt/projects/e-mental-health/usb/releases/20191217/\"\n",
    "ANOSTRING = \"-an\"\n",
    "GZEXTENSION = \".gz\"\n",
    "XMLEXTENSION = \".xml\"\n",
    "\n",
    "os.chdir(ANODIRECTORY)\n",
    "\n",
    "def shortenFileName(fileName):\n",
    "    fileName = re.sub(GZEXTENSION,\"\",fileName)\n",
    "    fileName = re.sub(XMLEXTENSION,\"\",fileName)\n",
    "    fileName = re.sub(ANOSTRING,\"\",fileName)   \n",
    "    return(fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LASTFILENBR = 1987\n",
    "\n",
    "def getAllTactusMails():\n",
    "    allMails = {}\n",
    "    missingFiles = []\n",
    "    for patientId in list(range(1,LASTFILENBR+1)):\n",
    "        if patientId % 100 == 0: print(patientId,end=\" \")\n",
    "        fileName = tactusloaderLIB.makeFileName(str(patientId))+GZEXTENSION\n",
    "        if os.path.isfile(ANODIRECTORY+fileName):\n",
    "            mails = tactusloaderLIB.processFile(ANODIRECTORY,fileName)\n",
    "            if len(mails[0]) > 0:\n",
    "                sortedMails = OWEmailSorterLIB.filterEmails(mails[0],filter_asc=True)\n",
    "                markedMails = markduplicatesLIB.processCorpus(sortedMails)\n",
    "                strippedMails = removemarkedtextLIB.processCorpus(markedMails)\n",
    "                allMails[shortenFileName(fileName)] = strippedMails\n",
    "        else: missingFiles.append(fileName)\n",
    "    if len(missingFiles) > 0: print(\"\\nmissing files:\",missingFiles)\n",
    "    return(allMails)\n",
    "\n",
    "allMails = getAllTactusMails()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need labels for the data. We will use the dropout labels provided by a student's project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECTEDFILE = \"/home/erikt/projects/e-mental-health/usb/releases/20200305/selected.csv.gz\"\n",
    "DROPOUT = \"dropout\"\n",
    "FILE = \"file\"\n",
    "NBROFDROPOUTS = 791\n",
    "\n",
    "dropouts = {}\n",
    "inFile = gzip.open(SELECTEDFILE,\"rt\",encoding=\"utf-8\")\n",
    "csvreader = csv.DictReader(inFile)\n",
    "for row in csvreader:\n",
    "    row[FILE] = re.sub(\"(-an)?.xml(.gz)?$\",\"\",row[FILE])\n",
    "    if row[DROPOUT] == \"1\" or row[DROPOUT] == \"2\": \n",
    "        dropouts[row[FILE]] = row[DROPOUT]\n",
    "inFile.close()\n",
    "\n",
    "len(dropouts) == NBROFDROPOUTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fasttext operates on files so we should store our data in a file to enable fasttext to access it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "COUNSELOR = \"COUNSELOR\"\n",
    "FROMFIELD = \"from\"\n",
    "LABELPREFIX = \"__label__\"\n",
    "OUTFILENAME = \"fasttext.txt\"\n",
    "\n",
    "def getFieldId(corpus,fieldName):\n",
    "    fieldId = -1\n",
    "    for i in range(0,len(corpus.domain.metas)):\n",
    "        if str(corpus.domain.metas[i]) == fieldName:\n",
    "            fieldId = i\n",
    "    return(fieldId)\n",
    "\n",
    "def getLastCounselorMailId(allMails,clientId):\n",
    "    for i in range(-1,-len(allMails[clientId])-1,-1):\n",
    "        if allMails[clientId][i][FROMFIELD] == COUNSELOR: return(i)\n",
    "    sys.exit(\"getLastCounselortMailId: client \"+clientId+\" did not receive any emails!\")\n",
    "\n",
    "def selectLastCounselorMail(allMails):\n",
    "    selectedData = []\n",
    "    selectedLabels = []\n",
    "    if len(allMails) > 0:\n",
    "        firstClient = list(allMails.keys())[0]\n",
    "        subjectId = getFieldId(allMails[firstClient],\"subject\")\n",
    "        textId = getFieldId(allMails[firstClient],\"text\")\n",
    "        for clientId in allMails:\n",
    "            if clientId in dropouts:\n",
    "                lastCounselorMailId = getLastCounselorMailId(allMails,clientId)\n",
    "                subject = allMails[clientId][lastCounselorMailId].metas[subjectId]\n",
    "                mailText = allMails[clientId][lastCounselorMailId].metas[textId]\n",
    "                selectedLabels.append(dropouts[clientId])\n",
    "                selectedData.append(subject+\" \"+mailText)\n",
    "    return(selectedData,selectedLabels)\n",
    "\n",
    "def storeTactusDataInFastTextFile(X,y,outFileName):\n",
    "    if len(X) != len(y): \n",
    "        sys.exit(\"storeTactusDataInFastTextFile(): incompatable lengths of X and y\")\n",
    "    outFile = open(outFileName,\"w\")\n",
    "    for i in range(0,len(X)):\n",
    "        print(LABELPREFIX+str(y[i]),X[i],file=outFile)\n",
    "    outFile.close()\n",
    "    return()\n",
    "\n",
    "def shuffleXy(X,y):\n",
    "    if len(X) != len(y): sys.exit(\"shuffleXy(): incompatable lengths of X and y\")\n",
    "    shuffledX = []\n",
    "    shuffledY = []\n",
    "    while len(X) > 0:\n",
    "        r = random.randint(0,len(X)-1)\n",
    "        shuffledX.append(X[r])\n",
    "        shuffledY.append(y[r])\n",
    "        X[r] = X[0]\n",
    "        y[r] = y[0]\n",
    "        X.pop(0)\n",
    "        y.pop(0)\n",
    "    return(shuffledX,shuffledY)\n",
    "    \n",
    "selectedData,selectedLabels = selectLastCounselorMail(allMails)\n",
    "X,y = shuffleXy(selectedData,selectedLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can start a fasttext experiment using this data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBROFFOLDS = 5\n",
    "foldBoundaries = [round((f)*len(X)/NBROFFOLDS) for f in range(0,NBROFFOLDS+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM = 300\n",
    "EPOCHSTART = 30\n",
    "EPOCHEND = 31\n",
    "EPOCHSTEP = 5\n",
    "TRAINFILE = \"fasttext-train.txt\"\n",
    "TESTFILE = \"fasttext-test.txt\"\n",
    "WIKIFILENAME = \"wiki.nl.vec\"\n",
    "CCFILENAME = \"cc.nl.300.vec\"\n",
    "WIKIDIR = \"/home/erikt/projects/newsgac/fasttext-runs/\"\n",
    "\n",
    "def fasttextPredict(X,y,epochStart,epochEnd,epochStep):\n",
    "    predictions = {str(epoch):[] for epoch in range(EPOCHSTART,EPOCHEND,EPOCHSTEP)}\n",
    "    for f in range(0,NBROFFOLDS):\n",
    "        startTest = foldBoundaries[f]\n",
    "        endTest = foldBoundaries[f+1]\n",
    "        storeTactusDataInFastTextFile(X[startTest:endTest],y[startTest:endTest],TESTFILE)\n",
    "        storeTactusDataInFastTextFile(X[:startTest]+X[endTest:],y[:startTest]+y[endTest:],TRAINFILE)\n",
    "        for epoch in range(epochStart,epochEnd,epochStep):\n",
    "            model = fasttext.train_supervised(ANODIRECTORY+TRAINFILE,dim=DIM,epoch=epoch) \n",
    "                                            # pretrainedVectors=WIKIDIR+WIKIFILENAME)\n",
    "            testFile = open(TESTFILE,\"r\")\n",
    "            for line in testFile:\n",
    "                tokens = line.strip().split()\n",
    "                if re.search(\"^\"+LABELPREFIX,tokens[0]): tokens.pop(0)\n",
    "                line = \" \".join(tokens)\n",
    "                predictions[str(epoch)].append(re.sub(LABELPREFIX,\"\",model.predict(line)[0][0]))\n",
    "            testFile.close()\n",
    "    return(predictions)\n",
    "\n",
    "predictions = fasttextPredict(X,y,EPOCHSTART,EPOCHEND,EPOCHSTEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "uniqueCounts = np.unique(y,return_counts=True)\n",
    "totals = {list(uniqueCounts[0])[i]:list(uniqueCounts[1])[i] for i in range(0,len(uniqueCounts[0]))}\n",
    "totals['0'] = len(y)\n",
    "\n",
    "for epoch in predictions:\n",
    "    counts = {'0':0,'1':0,'2':0}\n",
    "    for i in range(0,len(predictions[epoch])):\n",
    "        if predictions[epoch][i] == y[i]: \n",
    "            counts['0'] += 1\n",
    "            counts[y[i]] += 1\n",
    "    print(epoch,end = \" # \")\n",
    "    for key in counts: print(key,\":\",round(counts[key]/totals[key],3),end=\"; \",sep=\"\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When trying to predict dropout based on the final counselor mail, using a Wikipedia dictionary did not improve accuracy (83.7% vs 85.2%), at least not when training 30 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model explanation\n",
    "\n",
    "Find out which tokens contribute to which classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storeTactusDataInFastTextFile(X,y,TRAINFILE)\n",
    "model = fasttext.train_supervised(ANODIRECTORY+TRAINFILE,dim=DIM,epoch=EPOCHSTART)\n",
    "\n",
    "seen = {}\n",
    "predictions = {}\n",
    "for mailText in X:\n",
    "    for token in mailText.split():\n",
    "        if not token in seen:\n",
    "            seen[token] = True\n",
    "            labels,scores = model.predict(token)\n",
    "            for i in range(0,len(labels)):\n",
    "                label = list(labels)[i]\n",
    "                score = list(scores)[i]\n",
    "                if not label in predictions: predictions[label] = {}\n",
    "                predictions[label][token] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predictions[\"__label__1\"]),len(predictions[\"__label__2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted1 = {k: v for k, v in sorted(predictions[\"__label__1\"].items(), key=lambda item: item[1], reverse=True)}\n",
    "{ key:sorted1[key] for key in list(sorted1.keys())[0:20] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted2 = {k: v for k, v in sorted(predictions[\"__label__2\"].items(), key=lambda item: item[1], reverse=True)}\n",
    "{ key:sorted2[key] for key in list(sorted2.keys())[0:20] }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many more tokens that trigger the largest class (1/dropout) rather than the smallest (2/finisher; about 3200 vs about 80). The tokens with the highest scores according to fastText do not seem very interesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-orange",
   "language": "python",
   "name": "python-orange"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
